{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01fd0d89",
   "metadata": {},
   "source": [
    "Amazon Web Scraping Using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d58d7ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "# smtplib is used to send emails to yourself\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import smtplib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feb0ceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to tell beautiful soup where to get the data from\n",
    "\n",
    "URL = 'https://www.amazon.ca/Analyst-Definition-Scientist-Computer-Science/dp/B0CG2L51GZ'\n",
    "\n",
    "# we will need headers\n",
    "# get user-agent\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36 OPR/109.0.0.0\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "    \"DNT\": \"1\",\n",
    "    \"Connection\": \"close\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\"\n",
    "}\n",
    "\n",
    "# we are requesting -> pulling the data from the webpage and using the libraries\n",
    "page = requests.get(URL, headers=headers)\n",
    "\n",
    "# we will now use the soup library\n",
    "soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# this will pull all the html on the webpage\n",
    "\n",
    "#print(soup1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d99fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.pretify function will make the html that's being pulled look 'pretty'\n",
    "# better format\n",
    "\n",
    "soup2 = BeautifulSoup(soup1.prettify(), 'html.parser')\n",
    "\n",
    "#print(soup2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9406f332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Analyst Tshirt Funny Definition Data Scientist Computer Science Gift T-Shirt for Men Women\n",
      "39\n",
      "                      \n",
      "                       .\n"
     ]
    }
   ],
   "source": [
    "# let's try to get the title of the listing item\n",
    "#use strip to get rid of trailing and leading spaces\n",
    "\n",
    "title = soup2.find(id='productTitle').get_text().strip()\n",
    "\n",
    "# let's also get the price of the item\n",
    "\n",
    "price= soup2.find('span',class_='a-price-whole').get_text().strip()\n",
    "\n",
    "print(title)\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7455db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-10\n"
     ]
    }
   ],
   "source": [
    "# its important to have a timestamp of when you collected the data\n",
    "# we will use the library from datatime package\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "print(today)\n",
    "\n",
    "# we are going to create a csv to copy the data into it\n",
    "# create csv\n",
    "\n",
    "import csv\n",
    "\n",
    "# we want headers \n",
    "# we also want data\n",
    "# we need to make sure our data is a list\n",
    "\n",
    "header = ['Title', 'Price', 'Date']\n",
    "\n",
    "# we need to make sure our data is a list\n",
    "data = [title,price,today]\n",
    "\n",
    "#type(data) to check is its a list\n",
    "\n",
    "# create csv and name it\n",
    "# 'w' means write\n",
    "# newline -> when we insert data we want space\n",
    "# everythingelse is default plug ins\n",
    "\n",
    "with open('AmazonWebScraperProject.csv', 'w', newline ='', encoding ='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # create header, the inital insertion of the data\n",
    "    writer.writerow(header)\n",
    "    # inserting data\n",
    "    writer.writerow(data)\n",
    "    \n",
    "# this will create  csv file in the specified jupyter folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ab38964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  \\\n",
      "0  Data Analyst Tshirt Funny Definition Data Scie...   \n",
      "\n",
      "                                               Price        Date  \n",
      "0  39\\n                      \\n                  ...  2024-05-10  \n"
     ]
    }
   ],
   "source": [
    "# we are going to create a df for the csv we just created\n",
    "# instead of opening the file everytime we can just use python to open it \n",
    "\n",
    "df = pd.read_csv(r'/Users/abu/Data Science Bootcamp/Python for Data Science/AmazonWebScraperProject.csv')\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10f1f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming you want to get data over time\n",
    "# we can appeding data to the csv\n",
    "# use a+ to append data to the csv\n",
    "# we can also automate this step instead of running the script everytime \n",
    "# it can run in the background\n",
    "\n",
    "\n",
    "with open('AmasonWebScraperProject.csv', 'a+', newline ='', encoding ='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(data)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01ff1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# everything we just wrote we will need to plug it in the function below\n",
    "# we will use this function we make on a timer\n",
    "\n",
    "\n",
    "def check_price():\n",
    "    URL = 'https://www.amazon.ca/Analyst-Definition-Scientist-Computer-Science/dp/B0CG2L51GZ'\n",
    "    \n",
    "    headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36 OPR/109.0.0.0\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "    \"DNT\": \"1\",\n",
    "    \"Connection\": \"close\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\"\n",
    "    }\n",
    "    \n",
    "    page = requests.get(URL, headers=headers)\n",
    "    \n",
    "    soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
    "    \n",
    "    soup2 = BeautifulSoup(soup1.prettify(), 'html.parser')\n",
    "    \n",
    "    title = soup2.find(id='productTitle').get_text().strip()\n",
    "    \n",
    "    price= soup2.find('span',class_='a-price-whole').get_text().strip()\n",
    "\n",
    "    #import datatime\n",
    "    \n",
    "    today = datetime.date.today()\n",
    "    \n",
    "    import csv\n",
    "    \n",
    "    header = ['Title', 'Price', 'Date']\n",
    "    data = [title,price,today]\n",
    "    \n",
    "    with open('AmazonWebScraperProject.csv', 'a+', newline ='', encoding ='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c8209cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# let's make a while loop\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# let's update the timer every day\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# we can also you a certain price point for which if the item hits, we can email ourselves to point the drop\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m----> 6\u001b[0m     check_price()\n\u001b[1;32m      7\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m86400\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# we can also you a certain price point for which if the item hits, we can email ourselves to point the drop\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# if the price drops to 30 it will send us an email\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[21], line 25\u001b[0m, in \u001b[0;36mcheck_price\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m soup2 \u001b[38;5;241m=\u001b[39m BeautifulSoup(soup1\u001b[38;5;241m.\u001b[39mprettify(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m title \u001b[38;5;241m=\u001b[39m soup2\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproductTitle\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget_text()\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m---> 25\u001b[0m price\u001b[38;5;241m=\u001b[39m soup2\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m,class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma-price-whole\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget_text()\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#import datatime\u001b[39;00m\n\u001b[1;32m     29\u001b[0m today \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdate\u001b[38;5;241m.\u001b[39mtoday()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text'"
     ]
    }
   ],
   "source": [
    "\n",
    "# let's make a while loop\n",
    "# let's update the timer every day\n",
    "# we can also you a certain price point for which if the item hits, we can email ourselves to point the drop\n",
    "\n",
    "while(True):\n",
    "    check_price()\n",
    "    time.sleep(86400)\n",
    "    \n",
    "# we can also you a certain price point for which if the item hits, we can email ourselves to point the drop\n",
    "# if the price drops to 30 it will send us an email\n",
    "\n",
    "    if(price < 30):\n",
    "        send_mail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60da8124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If uou want to try sending yourself an email (just for fun) when a price hits below a certain level you can try it out with this script\n",
    "\n",
    "def send_mail():\n",
    "    server = smtplib.SMTP_SSL('smtp.gmail.com',465)\n",
    "    server.ehlo()\n",
    "    #server.starttls()\n",
    "    server.ehlo()\n",
    "    server.login('abugetthecar@gmail.com','xxxxxxxxxxxxxx')\n",
    "    \n",
    "    subject = \"The Shirt you want is below $30! Now is your chance to buy!\"\n",
    "    body = \"Abu, This is the moment we have been waiting for. Now is your chance to pick up the shirt of your dreams. Don't mess it up! Link here: https://www.amazon.ca/Analyst-Definition-Scientist-Computer-Science/dp/B0CG2JHH2L?th=1&psc=1\"\n",
    "   \n",
    "    msg = f\"Subject: {subject}\\n\\n{body}\"\n",
    "    \n",
    "    server.sendmail(\n",
    "        'abugetthecar@gmail.com',\n",
    "        msg\n",
    "     \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c07c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'/Users/abu/Data Science Bootcamp/Python for Data Science/AmazonWebScraperProject.csv')\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ce1f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54370abd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
